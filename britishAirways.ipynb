{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapping for sentiment data from an airline website for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "Done writing reviews to CSV file\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# specify the base URL of the page to be scraped\n",
    "base_url = 'https://www.airlinequality.com/airline-reviews/british-airways/page/'\n",
    "\n",
    "# specify the number of pages to scrape\n",
    "num_pages = 10\n",
    "\n",
    "# specify the page size\n",
    "page_size = 1000\n",
    "\n",
    "# create an empty list to store the reviews\n",
    "reviews = []\n",
    "\n",
    "# loop through each page to be scraped\n",
    "for page_num in range(1, num_pages + 1):\n",
    "\n",
    "    # specify the URL of the page to be scraped\n",
    "    url = base_url + str(page_num) + '/?sortby=post_date%3ADesc&pagesize=' + str(page_size)\n",
    "\n",
    "    # send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # loop through each review on the page and extract the review text\n",
    "    for review in soup.find_all('div', class_='text_content'):\n",
    "        review_text = review.get_text(strip=True)\n",
    "        reviews.append(review_text)\n",
    "\n",
    "    print('Scraped page', page_num)\n",
    "\n",
    "# create a CSV file and write the reviews to it\n",
    "with open('british-airways-reviews.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Review'])\n",
    "    for review in reviews:\n",
    "        writer.writerow([review])\n",
    "\n",
    "print('Done writing reviews to CSV file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Define the base URL and number of pages to scrape\n",
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "num_pages = 10\n",
    "page_size = 100\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to analyze the sentiment of a given text\n",
    "def analyze_sentiment(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "# Initialize the list of reviews\n",
    "reviews = []\n",
    "\n",
    "# Scrape the reviews from each page\n",
    "for i in range(1, num_pages + 1):\n",
    "    # Define the URL for the current page\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Retrieve the HTML content\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    # Extract the review text and add it to the list of reviews\n",
    "    for review in soup.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        text = review.get_text().strip()\n",
    "        sentiment = analyze_sentiment(text)\n",
    "        reviews.append({'text': text, 'sentiment': sentiment})\n",
    "\n",
    "# Write the reviews to a CSV file\n",
    "with open('reviews.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['text', 'sentiment']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for review in reviews:\n",
    "        writer.writerow({'text': review['text'], 'sentiment': review['sentiment']})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
